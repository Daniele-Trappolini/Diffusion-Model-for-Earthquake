{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import random\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy.imaging.spectrogram import spectrogram\n",
    "from torchmetrics import ScaleInvariantSignalDistortionRatio\n",
    "from torchmetrics import SignalNoiseRatio\n",
    "from torchmetrics.audio import SignalDistortionRatio\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import seisbench.models as sbm\n",
    "from obspy import Stream,Trace\n",
    "import argparse\n",
    "\n",
    "import Utils.utils_diff as u\n",
    "import Utils.utils_models as um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Args Parser ###\n",
    "def read_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--dataset_path\",\n",
    "                        default='c:\\\\Users\\\\dantr\\\\Desktop\\\\Github\\\\Dataset\\\\Train\\\\')\n",
    "    \n",
    "    parser.add_argument(\"--checkpoint_path\",\n",
    "                        default='C:\\\\Users\\\\dantr\\\\Desktop\\\\Github\\\\source\\\\Test\\\\Checkpoint\\\\Unet_1Channel\\\\')\n",
    "    \n",
    "    parser.add_argument(\"--ch\",\n",
    "                        default=0,\n",
    "                        type=int,\n",
    "                        help=\"number of channel\")\n",
    "    \n",
    "    parser.add_argument(\"--TRACE_SIZE\",\n",
    "                        default=2496,\n",
    "                        type=int,\n",
    "                        help=\"trace size (default: 3000)\")\n",
    "    \n",
    "        \n",
    "    parser.add_argument(\"--T\",\n",
    "                        default=300,\n",
    "                        type=int,\n",
    "                        help=\"Timesteps (default: 300)\")\n",
    "    \n",
    "    parser.add_argument(\"--batch_size\",\n",
    "                        default=16,\n",
    "                        type=int,\n",
    "                        help=\"Batch size (default: 16)\")\n",
    "\n",
    "    parser.add_argument(\"--signal_start\",\n",
    "                        default=700,\n",
    "                        type=int,\n",
    "                        help=\"signal_start (default: 700)\")\n",
    "    \n",
    "    parser.add_argument(\"--lr\",\n",
    "                        default=0.0001,\n",
    "                        type=float,\n",
    "                        help=\"learning rate (default: 0.0001)\")\n",
    "    \n",
    "    parser.add_argument(\"--train_percentage\",\n",
    "                        default=0.90,\n",
    "                        type=float,\n",
    "                        help=\"train_percentage (default: 0.95)\")\n",
    "    \n",
    "    parser.add_argument(\"--val_percentage\",\n",
    "                        default=0.05,\n",
    "                        type=float,\n",
    "                        help=\"val_percentage (default: 0.025)\")\n",
    "    \n",
    "    parser.add_argument(\"--test_percentage\",\n",
    "                        default=0.05,\n",
    "                        type=float,\n",
    "                        help=\"test_percentage (default: 0.025)\")\n",
    "    \n",
    "    parser.add_argument(\"--seed\",\n",
    "                        default=1234,\n",
    "                        type=int,\n",
    "                        help=\"seed (default: 1234)\")\n",
    "    \n",
    "    parser.add_argument(\"--epochs\",\n",
    "                        default=200,\n",
    "                        type=int,\n",
    "                        help=\"epochs (default: 200)\")\n",
    "    \n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args() # Questo solo per jupyter notebook \n",
    "    \n",
    "    return args\n",
    "\n",
    "args = read_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda\" \n",
    "    map_location=None\n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "    map_location='cpu'\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seeds\n",
      "len(df noise_train) 500 len(df train) 500\n"
     ]
    }
   ],
   "source": [
    "u.seed_everything(args.seed)\n",
    "force_traces_in_test=[]\n",
    "num_classes=2\n",
    "\n",
    "df = pd.read_pickle(args.dataset_path+\"df_train.csv\")\n",
    "df = df[:500]\n",
    "df=df.drop(columns=[\"level_0\"])\n",
    "df_noise = pd.read_pickle(args.dataset_path+\"df_noise_train.csv\")\n",
    "df_noise = df_noise[:500]\n",
    "print(\"len(df noise_train)\",len(df_noise),\"len(df train)\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events in train dataset:  449\n",
      "Events in validation dataset:  25\n",
      "Events in test dataset:  26\n",
      "Computing E channel\n",
      "Computing N channel\n",
      "Computing Z channel\n",
      "Computing index\n",
      "dataset_trainindex.shape[1] 1\n",
      "X_train.shape:  (449, 2496, 3)\n",
      "index_train.shape:  (449, 1)\n",
      "X_val.shape:  (25, 2496, 3)\n",
      "index_val.shape:  (25, 1)\n",
      "X_test.shape:  (26, 2496, 3)\n",
      "index_test.shape:  (26, 1)\n",
      "data samples in tr_dl:  449\n"
     ]
    }
   ],
   "source": [
    "df, X_train, index_train, X_val, index_val, X_test, index_test= u.train_val_test_split(df, signal_start=args.signal_start, signal_end=args.signal_start+args.TRACE_SIZE, train_percentage=args.train_percentage, val_percentage=args.val_percentage, test_percentage=args.test_percentage,force_in_test=force_traces_in_test)\n",
    "tr_dl = u.create_dataloader(X=X_train, y=X_train, index=index_train,target_dataset=\"train_dataset\", batch_size=args.batch_size,normalize_data=True)\n",
    "val_dl = u.create_dataloader(X=X_val, y=X_val, index=index_val,target_dataset=\"val_dataset\", batch_size=args.batch_size,normalize_data=True)\n",
    "test_dl = u.create_dataloader(X=X_test, y=X_test, index=index_test,target_dataset=\"test_dataset\", batch_size=args.batch_size,normalize_data=True)\n",
    "print(\"data samples in tr_dl: \", len(tr_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events in train dataset:  450\n",
      "Events in validation dataset:  25\n",
      "Events in test dataset:  25\n",
      "Computing E channel\n",
      "Computing N channel\n",
      "Computing Z channel\n",
      "Computing index\n",
      "dataset_trainindex.shape[1] 1\n",
      "X_train.shape:  (450, 2496, 3)\n",
      "index_train.shape:  (450, 1)\n",
      "X_val.shape:  (25, 2496, 3)\n",
      "index_val.shape:  (25, 1)\n",
      "X_test.shape:  (25, 2496, 3)\n",
      "index_test.shape:  (25, 1)\n",
      "data samples in tr_dl:  450\n"
     ]
    }
   ],
   "source": [
    "df_noise, X_train_noise, index_train_noise, X_val_noise, index_val_noise, X_test_noise, index_test_noise=u.train_val_test_split(df_noise, signal_start=args.signal_start, signal_end=args.signal_start+args.TRACE_SIZE, train_percentage=args.train_percentage, val_percentage=args.val_percentage, test_percentage=args.test_percentage,force_in_test=[])\n",
    "tr_dl_noise = u.create_dataloader(X=X_train_noise, y=X_train_noise, index=index_train_noise,target_dataset=\"train_dataset\", batch_size=args.batch_size)\n",
    "val_dl_noise = u.create_dataloader(X=X_val_noise, y=X_val_noise, index=index_val_noise,target_dataset=\"val_dataset\", batch_size=args.batch_size)\n",
    "test_dl_noise = u.create_dataloader(X=X_test_noise, y=X_test_noise, index=index_test_noise,target_dataset=\"test_dataset\", batch_size=args.batch_size)\n",
    "print(\"data samples in tr_dl: \", len(tr_dl_noise.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define beta schedule\n",
    "betas = u.linear_beta_schedule(timesteps=args.T)\n",
    "\n",
    "# Pre-calculate different terms for closed form\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = um.SimpleUnetPosEnc()\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "min_loss = np.Inf\n",
    "max_si_sdr = -np.Inf\n",
    "si_sdr = ScaleInvariantSignalDistortionRatio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2b6867353c4e569807a187f734b290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3532\\4019167621.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#aggiunto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mnoise_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoise_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRACE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRACE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mreduce_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    model.train() \n",
    "    for step, (batch, noise_in) in tqdm(enumerate(zip(tr_dl, tr_dl_noise)),total = len(tr_dl)):\n",
    "        t=torch.Tensor([0]).type(torch.int64)\n",
    "        model.zero_grad()  #aggiunto\n",
    "        optimizer.zero_grad()\n",
    "        noise_in = noise_in[0].permute(0,2,1).float()[:,args.ch,:].reshape(args.batch_size,1,args.TRACE_SIZE).to(device)\n",
    "        x=batch[0].permute(0,2,1).float()[:,args.ch,:].reshape(args.batch_size,1,args.TRACE_SIZE).to(device)\n",
    "        reduce_noise = random.randint(40, 65)*0.01\n",
    "        noise_in=noise_in*reduce_noise\n",
    "        earthqk_noise=x+noise_in\n",
    "        out = model(earthqk_noise.to(device), t.to(device))\n",
    "        noise_in_pred=out[:,0,:]\n",
    "        eq_pred=out[:,1,:]\n",
    "        loss_noise_in=F.l1_loss(noise_in, noise_in_pred.reshape(args.batch_size,1,args.TRACE_SIZE))\n",
    "        loss_eq= F.l1_loss(x, eq_pred.reshape(args.batch_size,1,args.TRACE_SIZE))\n",
    "        loss_mix= F.l1_loss(earthqk_noise, eq_pred.reshape(args.batch_size,1,args.TRACE_SIZE)+noise_in_pred.reshape(args.batch_size,1,args.TRACE_SIZE))\n",
    "        loss=loss_eq+loss_noise_in+loss_mix\n",
    "          \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"loss train\", loss.item())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sum_si_sdr_val = 0\n",
    "        sum_val_loss=0\n",
    "        for step, batch in tqdm(enumerate(val_dl), total=len(val_dl)):\n",
    "            t=torch.Tensor([0]).type(torch.int64)\n",
    "            noise_in = next(iter(val_dl_noise))[0].permute(0,2,1).float()[:,args.ch,:].reshape(args.batch_size,1,args.TRACE_SIZE).to(device)\n",
    "            x=batch[0].permute(0,2,1).float()[:,args.ch,:].reshape(args.batch_size,1,args.TRACE_SIZE).to(device)\n",
    "            reduce_noise=random.randint(40, 65)*0.01\n",
    "            noise_in=noise_in*reduce_noise\n",
    "            earthqk_noise=x+noise_in\n",
    "            out = model(earthqk_noise.to(device), t.to(device))\n",
    "            noise_in_pred=out[:,0,:]\n",
    "            eq_pred=out[:,1,:]\n",
    "            sum_si_sdr_val += si_sdr(x.cpu(), eq_pred.reshape(args.batch_size,1,args.TRACE_SIZE).cpu())\n",
    "            curr_si_sdr= sum_si_sdr_val/len(val_dl)\n",
    "            print(\"curr_si_sdr\",curr_si_sdr,\" max_si_sdr\",max_si_sdr)\n",
    "            loss_noise_in=F.l1_loss(noise_in, noise_in_pred.reshape(args.batch_size,1,args.TRACE_SIZE))\n",
    "            loss_eq= F.l1_loss(x, eq_pred.reshape(args.batch_size,1,args.TRACE_SIZE))\n",
    "            loss_mix= F.l1_loss(earthqk_noise, eq_pred.reshape(args.batch_size,1,args.TRACE_SIZE)+noise_in_pred.reshape(args.batch_size,1,args.TRACE_SIZE))\n",
    "            loss=loss_eq+loss_noise_in+loss_mix\n",
    "            print(\"loss val\", loss.item())\n",
    "            if curr_si_sdr > max_si_sdr:\n",
    "                print(\"Saving best epoch: \", epoch)\n",
    "                max_si_sdr = curr_si_sdr\n",
    "                torch.save(model.state_dict(), args.checkpoint_path+\"final_epoch\"+str(epoch)+\"UnetPosEmb.pt\")\n",
    "            print(\"model saved\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
